{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be7fa2d",
   "metadata": {},
   "source": [
    "In this notebook I prepare the xlxs files so that they are compatible to use with Centile (https://centilebrain.org/#/model)\n",
    "I take the cortical thickness extracted in extract_thickenss_info.sh and the demographics xlxs files and create the required xlxs for Centile divided by sex and HC/patient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3147fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a86c8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "RESOURCES_DIR = os.path.join(PROJECT_DIR, 'resources')\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, 'data')\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, 'raw')\n",
    "\n",
    "sys.path.append(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189df6d0",
   "metadata": {},
   "source": [
    "## Prepare the data for centile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed3deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import prepare_lut\n",
    "fs_default = prepare_lut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d151998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The template given by Centile\n",
    "template = pd.read_excel(f'{RESOURCES_DIR}/template_cortical_thickness.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fef390a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.utils\n",
    "importlib.reload (scripts.utils)\n",
    "from scripts.utils import get_raw_thickness\n",
    "gmv = get_raw_thickness(RAW_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb845dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My demo information\n",
    "demo1= pd.read_excel(f'{DATA_DIR}/demographics/Demographics_data.xlsx')\n",
    "demo2= pd.read_excel(f'{DATA_DIR}/demographics/Demographics_Test_data_2025.08.08.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the demo xlxs columns\n",
    "columns_to_keep1 = ['No', 'Sex', 'Age']\n",
    "demo1 = demo1[columns_to_keep1]\n",
    "demo1.rename(columns={'No': 'pid', 'Sex': 'sex', 'Age': 'age'}, inplace=True)\n",
    "\n",
    "sub2 = np.unique(demo2['SubID'])\n",
    "demo2 = demo2[(demo2['SubID'].isin(sub2)) & (demo2['Wave'] == 'Baseline')].copy()\n",
    "columns_to_keep2 = ['ScanID', 'Sex', 'Age']\n",
    "demo2 = demo2[columns_to_keep2]\n",
    "demo2.rename(columns={'ScanID': 'pid', 'Sex': 'sex', 'Age': 'age'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af961f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging them\n",
    "demo = pd.concat([demo1, demo2])\n",
    "demo['pid'] = demo['pid'].astype('str')\n",
    "demo.set_index('pid', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2be97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging demo and thickness information\n",
    "demo_and_gmv = pd.concat([demo, gmv.loc[demo.index]], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3104eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the two sexes\n",
    "from scripts.utils import adjust_thick_template\n",
    "\n",
    "m, f = adjust_thick_template(demo_and_gmv, template)\n",
    "\n",
    "m.to_excel(f'{DATA_DIR}/processed/male_chinese_all_cortical_thick.xlsx', index=False)\n",
    "f.to_excel(f'{DATA_DIR}/processed/female_chinese_all_cortical_thick.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba926ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only healthy controls\n",
    "hc = ['1855', '1856', '1857', '1858', '1859', '1860', '1861', '1862', '1863', '1864']\n",
    "hc_f = [patient for patient in hc if patient in f['SubjectID'].values]\n",
    "hc_m = [patient for patient in hc if patient in m['SubjectID'].values]\n",
    "m[m['SubjectID'].isin(hc_m)].to_excel(f'{DATA_DIR}/processed/male_chinese_hc_cortical_thick.xlsx', index=False)\n",
    "f[f['SubjectID'].isin(hc_f)].to_excel(f'{DATA_DIR}/processed/female_chinese_hc_cortical_thick.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d438b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the patients\n",
    "pat_f = [patient for patient in f['SubjectID'].values if patient not in hc]\n",
    "pat_m = [patient for patient in m['SubjectID'].values if patient not in hc]\n",
    "m[m['SubjectID'].isin(pat_m)].to_excel(f'{DATA_DIR}/processed/male_chinese_pat_cortical_thick.xlsx', index=False)\n",
    "f[f['SubjectID'].isin(pat_f)].to_excel(f'{DATA_DIR}/processed/female_chinese_pat_cortical_thick.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb90c96",
   "metadata": {},
   "source": [
    "## Run Cenitle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158f30fa",
   "metadata": {},
   "source": [
    "At this point I can run the Centile model and collect the results. \n",
    "I store the results in folders by giving them the same name of the xlxs file of input, plus the suffix _centile_results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeeee99",
   "metadata": {},
   "source": [
    "## Merge the results from Centile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6cb09",
   "metadata": {},
   "source": [
    "Now I can put together the results from the male and female csv file specifying which score to use (MAE, zscore, prediction,...). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30fb35a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing male_chinese_all_cortical_thick_centile_results\n",
      "Processing female_chinese_all_cortical_thick_centile_results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giacomopreti/Desktop/VBT/GMV/scripts/utils.py:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  fs_default = pd.read_csv(f'{resources_dir}/fs_default.txt', sep='\\s+', comment='#')\n"
     ]
    }
   ],
   "source": [
    "from scripts.utils import merge_centile_results\n",
    "\n",
    "PROCESSED_DIR = f\"{DATA_DIR}/processed\"\n",
    "all_dfs = []\n",
    "xlsx_files = ['male_chinese_all_cortical_thick', 'female_chinese_all_cortical_thick']\n",
    "score = 'zscore'\n",
    "\n",
    "df = merge_centile_results(xlsx_files, score, PROCESSED_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84b27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import rename_to_fs_lut_labels\n",
    "df = rename_to_fs_lut_labels(df, fs_default)\n",
    "df.to_csv(f'{PROCESSED_DIR}/{score}_full_chinese_all_cortical_thick.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "desuenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
